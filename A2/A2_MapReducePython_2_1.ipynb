{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86310418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split()\n",
    "    # increase counters\n",
    "    for word in words:\n",
    "        # write the results to STDOUT (standard output);\n",
    "        # what we output here will be the input for the\n",
    "        # Reduce step, i.e. the input for reducer.py\n",
    "        #\n",
    "        # tab-delimited; the trivial word count is 1\n",
    "        print('%s\\t%s' % (word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"reducer.py\"\"\"\n",
    "\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "# input comes from STDIN\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "\n",
    "    # parse the input we got from mapper.py\n",
    "    word, count = line.split('\\t')\n",
    "\n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    "\n",
    "    # this IF-switch only works because Hadoop sorts map output\n",
    "    # by key (here: word) before it is passed to the reducer\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            # write result to STDOUT\n",
    "            print( '%s\\t%s' % (current_word, current_count))\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "# do not forget to output the last word if needed!\n",
    "if current_word == word:\n",
    "    print('%s\\t%s' % (current_word, current_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e8c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "#Load Tweets\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "# Load and parse JsonObject from text file\n",
    "def read_input():\n",
    "    tweets_list = []\n",
    "    for jsonObject in sys.stdin:\n",
    "        #Ignore Space in text file\n",
    "        if not jsonObject.isspace():\n",
    "                tweets_Dict = json.loads(jsonObject)\n",
    "                tweets_list.append(tweets_Dict)\n",
    "\n",
    "    tweet_data_frame = pd.DataFrame.from_dict(tweets_list)\n",
    "    # Lowercase of column \"TEXT\"\n",
    "    tweet_data_frame[\"text\"] = tweet_data_frame[\"text\"].apply(lambda str: str.lower())\n",
    "    # Delete Retweets based on retweeted attribute\n",
    "    tweet_unique = tweet_data_frame[tweet_data_frame.retweeted == False]\n",
    "    return tweet_unique[\"text\"]\n",
    "\n",
    "def mapper():\n",
    "    # Pattern of word allows no letter from a to z before and after the word \n",
    "    hen_patter = re.compile(\"[^a-z]hen[^a-z]\")\n",
    "    han_patter = re.compile(\"[^a-z]han[^a-z]\")\n",
    "    hon_patter = re.compile(\"[^a-z]hon[^a-z]\")\n",
    "    den_patter = re.compile(\"[^a-z]den[^a-z]\")\n",
    "    det_patter = re.compile(\"[^a-z]det[^a-z]\")\n",
    "    denna_patter = re.compile(\"[^a-z]denna[^a-z]\")\n",
    "    denne_patter = re.compile(\"[^a-z]denne[^a-z]\")\n",
    "    inputstream = read_input()\n",
    "    for index, line in inputstream.iteritems():\n",
    "        # Hen Patter\n",
    "        if hen_patter.search(line):\n",
    "            print(\"hen\\t1\")\n",
    "        # “han” Patter\n",
    "        if han_patter.search(line):\n",
    "            print(\"han\\t1\")\n",
    "        # HON\n",
    "        if hon_patter.search(line):\n",
    "            print(\"hon\\t1\")\n",
    "        # DEN\n",
    "        if den_patter.search(line):\n",
    "            print(\"den\\t1\")\n",
    "        # DET\n",
    "        if det_patter.search(line):\n",
    "            print(\"det\\t1\")\n",
    "        # DENNA\n",
    "        if denna_patter.search(line):\n",
    "            print(\"denna\\t1\")\n",
    "        # DENNE\n",
    "        if denne_patter.search(line):\n",
    "            print(\"denne\\t1\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # input comes from STDIN (standard input)\n",
    "    mapper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
